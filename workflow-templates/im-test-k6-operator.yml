# Workflow Code: ZestyAligator_v30   DO NOT REMOVE
# Purpose:
#    Runs K6 tests at scale in Azure Kubernetes.
#    With the workflow the user specifies when they kick it off manually.
#
# Frequency:
#    - This workflow is intended to be reusable, and used once per repository.
#
# Projects to use this Template with:
#    - App Service or Function (Optional Template)
#    - On-Prem Service         (Optional Template)
# # TODO: Prerequisites:
#    - Ensure each of the repo-level MS_TEAMS_URI and env-level secrets used in this workflow have been populated by an admin in your repository.

name: ðŸ§ªï¸ Run K6 Operator Test
run-name: Run K6 Operator Test to ${{ inputs.env }} with test ${{ inputs.test-file }}

on:
  workflow_dispatch:
    inputs:
      env:
        description: 'Environment to run test against [dev, qa, stage]'
        required: true
        type: choice
        options: # TODO: Update for the environments that are available.
          - dev
          - qa
          - load
          - stage
          - demo
      test-file:
        description: 'Test Filename: K6 js test file to run. Please include .js extension'
        required: true
        default: 'check-health-simple.js' # TODO: Update default test file
      upload-files-folder:
        description: 'Upload Files or Folders: Comma separated list of files or folders to include in the upload. Specify full path from working-directory root.'
        required: false
        default: '' # TODO: Update to default upload file or folder
      k6-parameters:
        description: 'K6 parameters:  This includes any tags or config files.'
        required: false
        default: '--tag product=TEST,family=TEST' # TODO: Update default tags for grafana dashboard filtering.
      parallelism:
        description: 'Parallelism: Number of Kubernetes Pods to run k6 tests on.'
        required: false
        default: '1'
      separate-nodes:
        description: 'Dedicated Node: Run each pod on individual node(VM). Warning: Coordinate with SRE before enabling.'
        required: false
        type: boolean
        default: false
      run-npm-build: # TODO: Delete input if you don't build your k6 tests with npm
        description: 'Run NPM Build: Run npm build to create packages k6 tests'
        required: false
        type: boolean
        default: false # TODO: Set true if you require npm build to run for your k6 bundle to be created
      output-to-prometheus:
        description: 'Output to Prometheus: Enable output to Prometheus.'
        required: false
        type: boolean
        default: false # TODO: Set default to true if you want to output to Prometheus by default
      loop-count:
        description: 'Loop Count: Number of loops to wait for test to complete.'
        required: false
        default: '50'
      maintenance-window-duration:
        description: 'Maintenance Window Duration: Duration of maintenance window in minutes. This should match your loop count'
        required: false
        default: '50' # TODO: Set default maintenance windows duration

permissions:
  # Required for secretless azure access and deploys
  id-token: write
  contents: read
  actions: read

env:
  TIMEZONE: 'america/denver'
  WORKING_DIRECTORY: './tests/k6'
  GRAFANA_INFLUXDB_DASHBOARD_URI: 'https://grafana.mktp.io/d/SizO_pC4k/k6-load-testing-results-with-env?orgId=1?&from=now-1h&to=now&var-ProductTag=SHOP&var-env=${{ inputs.env }}'
  GRAFANA_PROMETHEUS_DASHBOARD_URI: 'https://grafana.mktp.io/d/a3b2aaa8-bb66-4008-a1d8-16c49afedbf0/k6-prometheus-native-histograms?orgId=1&refresh=10s&var-quantile=0.99'
  NODE_VERSION: '20.x'

  K6_DEFAULT_PARAMETERS: "${{ inputs.output-to-prometheus && '--out experimental-prometheus-rw' || '--out influxdb=https://influxdb-v1.mktp.io/loadtesting' }} --insecure-skip-tls-verify --tag product=SHOP,family=EN,env=${{ inputs.env }} -e RUN_ENV=${{ inputs.env }}"
  # TODO: Optional add K6_PROMETHEUS_RW_STALE_MARKERS=true when running long load tests.  This variable will make short tests not show up in grafana
  K6_DEFAULT_ENVIRONMNET_VARIABLES: "K6_PROMETHEUS_RW_TREND_STATS=p(95),p(99),min,max;K6_PROMETHEUS_RW_SERVER_URL=http://prm-srv-prometheus-server.prometheus:80/api/v1/write;K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true"
  LOOP_DURATION: '1m' # TODO: Update duration of loop to your specification.  The action im-practices/run-k6-operator-test documenation has more details on setting this parameter.
  RETENTION_IN_DAYS: 1 # TODO: Set retention in days for uploaded artifacts
  K6_CONTAINER_IMAGE: 'perftest/k6:latest' # TODO: Update to k6 image version if using custom binary.  Uncomment reference in Run K6-Operator Test step to use.

  PAGERDUTY_WINDOW_IN_MIN: ${{ inputs.maintenance-window-duration }}
  PAGERDUTY_WINDOW_DESC: 'Running K6 Test on ${{ inputs.env }} from K6-Operator in AKS'

  # TODO: Set upload type.  Valid options are:
  # test-file # When running single test file
  # single-folder # When your tests reside in a single folder without dependencies
  # multiple-files # When you have multiple files even in different folders
  # multiple-folders # When you have multiple folders such as config and test-file folders
  # working-directory # Upload the whole directory you specified in the working directory input
  UPLOAD_TYPE: 'multiple-folders'

  ###### DO NOT EDIT ######
  PRIVATE_CONTAINER_REGISTRY: 'bdaimdna26corecr1.azurecr.io'
  CLUSTER_NAME: 'BDAIM-D-NA26-PERFTEST-K8-CL'
  CLUSTER_RESOURCE_GROUP: 'BDAIM-D-NA26-PerformanceTesting-RGRP'
  ###### DO NOT EDIT ######

jobs:
  # TODO: Delete if you don't build your k6 tests
  npm-cache:
    runs-on: [self-hosted, im-linux]
    if: inputs.run-npm-build

    defaults:
      run:
        shell: bash

    env:
      NPM_HASH_FILE: ${{ './${{ env.WORKING_DIRECTORY }}/package-lock.json' }}

    outputs:
      NPM_CACHE_key: ${{ env.NPM_CACHE_KEY }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref_name }}

      - name: Annotate Inputs
        run: |
          echo $'
          | Input Name            | Value                    |
          | ---                   |  ---                     |
          | Environment           | `${{ inputs.env }}` |
          | Workflow Branch/Tag   | `${{ github.ref_name }}` - SHA: `${{ github.sha }}` |
          | Working Directory     | `${{ env.WORKING_DIRECTORY }}` |
          | Test File             | `${{ inputs.test-file }}` |
          | Parallelism           | `${{ inputs.parallelism }}` |
          | Separate-nodes        | `${{ inputs.separate-nodes }}` |
          | Upload Type           | `${{ env.UPLOAD_TYPE }}` |
          | Upload File/Folders   | `${{ inputs.upload-files-folder }}` |
          | K6 Parameters         | `${{ inputs.k6-parameters }}` |
          | K6 Default Parameters | `${{ env.K6_DEFAULT_PARAMETERS }}`  |
          | Loop Count            | `${{ inputs.loop-count }}` |
          | Loop Duration         | `${{ env.LOOP_DURATION }}` |
          | Run NPM Build         | `${{ inputs.run-npm-build }}` |
          | Maintenance Window Duration | `${{ inputs.maintenance-window-duration }}` |' >> $GITHUB_STEP_SUMMARY

      - name: Set Cache Keys
        # As long as these files don't change the cache will remain in tact and the time
        # to restore the different packages in the various jobs will be reduced.  If one
        # of the files does change though, a new cache will be uploaded the next time
        # it runs, then subsequent runs should be faster.
        run: echo "NPM_CACHE_KEY=k6_node_modules-${{ hashFiles('./tests/k6/package-lock.json') }}" >> $GITHUB_ENV

      - name: Check for an npm cache
        id: has-cache
        uses: actions/cache@v4
        with:
          path: '**/k6/node_modules'
          key: ${{ env.NPM_CACHE_KEY }}
          lookup-only: true
          enableCrossOsArchive: true

      # The remaining steps will only be executed if the cache was not found, otherwise they will be skipped.

      # This action creates a post-job step that will upload the node_modules dir to the cache if the job
      # completes successfully.  Subsequent jobs and workflow runs can use this cached version of the node_modules
      # folder if the package-lock.json hasn't changed and it uses a im-linux runner to restore the cache from.
      # TODO: Delete if you don't build your k6 tests
      - name: Install Node ${{ env.NODE_VERSION }} if cache does not exist
        if: steps.has-cache.outputs.cache-hit != 'true'
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}

      # TODO:  If the project contains internal npm packages, uncomment and update the orgs with the needed organizations
      # - name: Authenticate with GitHub Packages if cache does not exist
      #   if: steps.has-cache.outputs.cache-hit != 'true'
      #   uses: im-open/authenticate-with-gh-package-registries@v1.1
      #   with:
      #     read-pkg-token: ${{ secrets.READ_PKG_TOKEN }} # This is an org-level secret
      #     orgs: ''
      
      - name: NPM Install
        if: steps.has-cache.outputs.cache-hit != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          echo "Installing NPM"
          npm ci

      - name: Save cache for node_modules directory
        if: steps.has-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          key: ${{ env.NPM_CACHE_KEY }}
          path: '**/k6/node_modules'
          enableCrossOsArchive: true

  run_k6_operator:
    runs-on: [self-hosted, im-linux]
    needs: [npm-cache] # TODO: Delete if you don't build your k6 tests
    environment: ${{ inputs.env }}

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref_name }}

      - name: Clean Test File Name for K6 Tag and Ouput Run Name
        id: test-tag
        run: |
          # Creating RunName
          k6_test_file="${{ inputs.test-file }}"
          k6_run_name="${k6_test_file/.js/''}"
          k6_run_name=$(echo $k6_run_name  | tr '/' '-')
          k6_run_name=$(echo $k6_run_name  | tr '.' '_')
          k6_run_name=$(echo $k6_run_name  | tr '_' '-')
          echo "run-name=$k6_run_name" >> $GITHUB_OUTPUT

      # TODO: Delete if you don't build your k6 tests
      - name: Install Node ${{ env.NODE_VERSION }}
        if: inputs.run-npm-build
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}

      # TODO: Delete if you don't build your k6 tests
      - name: Download npm cache
        uses: actions/cache/restore@v4
        if: inputs.run-npm-build
        with:
          key: ${{ needs.npm-cache.outputs.NPM_CACHE_KEY }}
          path: '**/k6/node_modules'
          enableCrossOsArchive: true
          fail-on-cache-miss: true

      # TODO: Delete if you don't build your k6 tests
      - name: Rebuild Node Modules
        if: inputs.run-npm-build
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: npm rebuild

      # TODO: Delete if you don't build your k6 tests
      - name: Build K6 Tests via npm build
        if: inputs.run-npm-build
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: npm run build

      - name: AZ Login
        uses: azure/login@v1
        with:
          # This is an org-level variable
          tenant-id: ${{ vars.ARM_TENANT_ID }}
          # These are env-level variables
          subscription-id: ${{ vars.ARM_SUBSCRIPTION_ID }}
          client-id: ${{ vars.ARM_CLIENT_ID }}

      # TODO: Delete if your runner has kubelogin and kubectl already installed
      - name: Setup Kubectl
        uses: azure/setup-kubectl@v3.2
        with:
          version: latest

      # TODO: Delete if your runner has kubelogin and kubectl already installed
      - name: Setup Kubelogin
        uses: azure/use-kubelogin@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          kubelogin-version: 'latest'

      - name: Setup kubectl config
        working-directory: ${{ env.WORKING_DIRECTORY }}
        id: kube-config
        run: |
          base_path=$(pwd)
          kube_config_file_path="$base_path/.kube/config-sp"
          export KUBECONFIG=$kube_config_file_path
          az aks get-credentials --name ${{ env.CLUSTER_NAME }} --resource-group ${{ env.CLUSTER_RESOURCE_GROUP }} --format exec --overwrite-existing --public-fqdn --file $kube_config_file_path
          kubelogin convert-kubeconfig --login azurecli --kubeconfig $kube_config_file_path

          echo "kube-config-file=$kube_config_file_path" >> $GITHUB_OUTPUT

          powerstate=$(az aks show --name ${{ env.CLUSTER_NAME }} --resource-group ${{ env.CLUSTER_RESOURCE_GROUP }} --query 'powerState.code' --out tsv)
          echo "cluster-powerstate=$powerstate" >> $GITHUB_OUTPUT
          echo "::notice title=Cluster Power State::Cluster Power State - $powerstate"

      - name: Stop test if Cluster is off
        if: steps.kube-config.outputs.cluster-powerstate != 'Running'
        run: exit 1

      - name: Open a PagerDuty Maintenance Window
        id: open-window
        uses: im-open/open-pagerduty-maintenance-window@v1
        with:
          pagerduty-api-key: ${{ secrets.PAGERDUTY_API_KEY }} # This is an org-level secret
          description: '${{ env.PAGERDUTY_WINDOW_DESC }}'
          minutes: ${{ env.PAGERDUTY_WINDOW_IN_MIN }}
          service-id: ${{ vars.PAGERDUTY_SERVICE_ID }} # This is an env-level variable
          #service-ids: '' # TODO: Provide a comma separated list if there are multiple ids. 'PD01,PD02,PD03'

      - name: Send Status to Teams - Starting Test
        continue-on-error: true
        uses: im-open/post-status-to-teams-action@v1
        with:
          title: 'K6 Test Starting Shortly in AKS - ${{ steps.test-tag.outputs.run-name }}'
          workflow-status: started
          workflow-type: Runbook
          teams-uri: ${{ vars.MS_TEAMS_URI }} # This is a repo-level secret (unless 'environment:' has been added to the job)
          timezone: ${{ env.TIMEZONE }}
          custom-facts: |
            [
              { "name": "Workflow", "value": "${{ github.workflow }}" },
              { "name": "Run", "value": "${{ github.run_id }}" },
              { "name": "Actor", "value": "${{ github.actor }}" },
              { "name": "Environment", "value": "${{ inputs.env }}"},
              { "name": "K6 Test", "value": "${{ inputs.test-file }}" }
            ]
          custom-actions: |
            [
              {
                "name": "View Grafana Dashboard",
                "uri": "${{ inputs.output-to-prometheus && env.GRAFANA_PROMETHEUS_DASHBOARD_URI || env.GRAFANA_INFLUXDB_DASHBOARD_URI }}"
              }
            ]

      - name: Run K6-Operator Test
        uses: im-practices/run-k6-operator-test@v3
        id: run-k6-operator-test
        with:
          working-directory: ${{ env.WORKING_DIRECTORY }}
          test-file: ${{ inputs.test-file }}
          run-name: ${{ steps.test-tag.outputs.run-name }}
          upload-type: ${{ env.UPLOAD_TYPE}}
          upload-files-folder: ${{ inputs.upload-files-folder }}
          k6-parameters: '${{ inputs.k6-parameters }}'
          k6-default-parameters: '${{ env.K6_DEFAULT_PARAMETERS }}'
          k6-environment-variables: "${{ env.K6_DEFAULT_ENVIRONMNET_VARIABLES }}"
          parallelism: ${{ inputs.parallelism }}
          separate-nodes: ${{ inputs.separate-nodes }}
          kube-config-file-path: ${{ steps.kube-config.outputs.kube-config-file }}
          retention-in-days: ${{ env.RETENTION_IN_DAYS }}
          loop-count: ${{ inputs.loop-count }}
          loop-duration: ${{ env.LOOP_DURATION }}
          # k6-extension-image: '${{ env.PRIVATE_CONTAINER_REGISTRY }}/${{ env.K6_CONTAINER_IMAGE }}' # TODO: uncomment to use custom k6 binary with k6 extensions installed
          # pod-log-lines-gha-output: 500 # TODO: uncomment if you want to change the number of lines in github actions that the pod logs output.
          # pod-log-lines-file-output: 3000 # TODO: uncomment if you want to change the number of lines to file that the pod logs output.

      ### Cleanup K6-Operator test if workflow is cancelled ###

      # Due to composite actions not supporting post steps, the following workflow steps are required to stop a k6-operator mid stream.
      - name: Upload K6 Deployment Json if Cancelled
        if: cancelled()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.run-k6-operator-test.outputs.deploy-json-artifact }}-bk
          path: ${{ steps.run-k6-operator-test.outputs.deploy-json-file }}
          retention-days: ${{ env.RETENTION_IN_DAYS }}

      - name: Stop Test if Workflow is Cancelled
        if: cancelled()
        continue-on-error: true
        shell: bash
        run: |
          kubectl delete testruns.k6.io/${{ steps.run-k6-operator-test.outputs.run-name }} --kubeconfig ${{ steps.kube-config.outputs.kube-config-file }} --namespace k6testing

      - name: Cleanup Test Configmap if Workflow is Cancelled
        if: cancelled()
        continue-on-error: true
        shell: bash
        run: |
          #  Cleanup Test Configmap

          echo ""
          echo "Deleting configmap: ${{ steps.run-k6-operator-test.outputs.config-map-name }}"
          kubectl delete configmap ${{ steps.run-k6-operator-test.outputs.config-map-name }} --kubeconfig ${{ steps.kube-config.outputs.kube-config-file }} --namespace k6testing

      ### Cleanup K6-Operator test if workflow is cancelled ###
      - name: Azure logout
        if: always()
        continue-on-error: true
        run: |
          az logout
          az cache purge
          az account clear

      - name: Remove kubectl config
        if: always()
        shell: bash
        working-directory: ${{ env.WORKING_DIRECTORY }}
        continue-on-error: true
        run: |
          # Remove kubectl config
          rm -rf ${{ steps.kube-config.outputs.kube-config-file }}

      - name: Close the PagerDuty Maintenance Window
        if: always()
        continue-on-error: true
        uses: im-open/close-pagerduty-maintenance-window@v1
        with:
          pagerduty-api-key: ${{ secrets.PAGERDUTY_API_KEY }} # This is an org-level secret
          maintenance-window-id: ${{ steps.open-window.outputs.maintenance-window-id }}

      - name: Send Status to Teams - Test Finished
        if: always()
        continue-on-error: true
        uses: im-open/post-status-to-teams-action@v1
        with:
          title: 'K6 Test in AKS Complete - ${{ steps.run-k6-operator-test.outputs.run-name }}'
          workflow-status: ${{ steps.run-k6-operator-test.outcome }}
          workflow-type: Runbook
          teams-uri: ${{ vars.MS_TEAMS_URI }} # This is a repo-level secret (unless 'environment:' has been added to the job)
          timezone: ${{ env.TIMEZONE }}
          custom-facts: |
            [
              { "name": "Workflow", "value": "${{ github.workflow }}" },
              { "name": "Run", "value": "${{ github.run_id }}" },
              { "name": "Actor", "value": "${{ github.actor }}" },
              { "name": "Environment", "value": "${{ inputs.env }}"},
              { "name": "K6 Test", "value": "${{ inputs.test-file }}" },
              { "name": "K6 Run Name w/Timestamp", "value": "${{ steps.run-k6-operator-test.outputs.run-name }}"},
              { "name": "K6 Cluster Powerstate", "value": "${{ steps.kube-config.outputs.cluster-powerstate }}"}
            ]
          custom-actions: |
            [
              {
                "name": "View Grafana Dashboard",
                "uri": "${{ inputs.output-to-prometheus && format('{0}&var-testid={1}',env.GRAFANA_PROMETHEUS_DASHBOARD_URI,steps.run-k6-operator-test.outputs.run-name) || env.GRAFANA_INFLUXDB_DASHBOARD_URI }}"
              }
            ]
