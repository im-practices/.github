# Workflow Code: InsaneHamster_v33    DO NOT REMOVE
# Purpose:
#    Deploys the terraform at a specified tag to a specified
#    environment when someone kicks off the build manually.
#
# Frequency:
#    - This workflow should only be used once per repository
#
# Projects to use this Template with:
#    - Terraform (Core Template)
#
# TODO: Prerequisites:
#    - Ensure each of the repo-level and env-level secrets used in this workflow have been populated by an admin in your repository.
#    - Set up a deployment board if it does not already exist: https://github.com/im-practices/git-er-done/blob/main/actions/deployment-board.md

name: Apply Terraform
run-name: Apply ${{ inputs.branch-tag-sha }} terraform to ${{ inputs.environment }}
on:
  workflow_dispatch:
    inputs:
      branch-tag-sha:
        description: The branch, tag or sha of the terraform that should be deployed.  For Production, only tags reachable by the default branch will be accepted.
        required: true
      environment:
        description: The environment to deploy to
        required: true
        type: choice
        options: # TODO: Update for the environments that are available
          - dev
          - qa
          - stage
          - demo
          - uat
          - prod

env:
  ENVIRONMENT: ${{ github.event.inputs.environment }}
  GITHUB_REF: ${{ github.event.inputs.branch-tag-sha  }} # This is the branch/tag/sha that we'll be deploying
  TIMEZONE: 'america/denver' # TODO: Verify timezone
  PLAN_STORAGE_CONTAINER: 'tfstate'
  # The following ARM_* secrets are org-level secrets
  ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
  ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
  ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
  ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
  ARM_ENVIRONMENT: 'public'
  TF_IN_AUTOMATION: 'true'
  TF_VERSION: '~>1.0.5' #TODO:  Verify your version of terraform.
  TF_WORKING_DIR: './infrastructure/${{ github.event.inputs.environment }}' # TODO: Verify this directory is correct for your repository (older projects may not be inside of an infrastructure folder)
  # The following SSH_* secrets are org-level secrets
  SSH_KEY_STORAGE_ACCOUNT: ${{ secrets.SSH_STORAGE_ACCOUNT }}
  SSH_KEY_NETWORK_INFO: ${{ secrets.SSH_NETWORK_INFO }}
  SSH_DEPLOY_KEY_INFO: |
    [
      { "orgAndRepo": "im-platform/storage-account-network-rules", "envName" : "SSH_KEY_STORAGE_ACCOUNT" },
      { "orgAndRepo": "im-platform/network-information", "envName" : "SSH_KEY_NETWORK_INFO" }
    ]

jobs:
  set-vars:
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners

    outputs:
      RESOURCE_GROUP: ${{ steps.set-variables.outputs.RESOURCE_GROUP }} # To use this value: ${{ needs.set-vars.outputs.RESOURCE_GROUP }}
      STORAGE_ACCOUNT: ${{ steps.set-variables.outputs.STORAGE_ACCOUNT }} # To use this value: ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }}

    steps:
      - run: |
          echo $'
          | Build Arguments | Value                    |
          | ---             |  ---                     |
          | Environment     | `${{ env.ENVIRONMENT }}` |
          | Branch/Tag/Sha  | `${{ env.GITHUB_REF }}`  |' >> $GITHUB_STEP_SUMMARY
      
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Verify Tag Exists
        uses: im-open/verify-git-ref@v1.2.0
        with:
          branch-tag-sha: ${{ env.GITHUB_REF }}

      # For more information and best practices on the usage and options available
      # for this action go to: https://github.com/im-open/set-environment-variables-by-scope#usage-instructions
      - name: Set Variables
        id: set-variables
        uses: im-open/set-environment-variables-by-scope@v1.1.2
        with:
          scope: ${{ env.ENVIRONMENT }}
          create-output-variables: true
        env:
          # This variable is used to upload and download blobs from blob storage
          RESOURCE_GROUP@dev: ''
          RESOURCE_GROUP@qa: ''
          RESOURCE_GROUP@stage: ''
          RESOURCE_GROUP@demo: ''
          RESOURCE_GROUP@uat: ''
          RESOURCE_GROUP@prod: ''
          # This variable is used to upload and download blobs from blob storage
          STORAGE_ACCOUNT@dev: ''
          STORAGE_ACCOUNT@qa: ''
          STORAGE_ACCOUNT@stage: ''
          STORAGE_ACCOUNT@demo: ''
          STORAGE_ACCOUNT@uat: ''
          STORAGE_ACCOUNT@prod: ''

  # Each env has their own stakeholder approval environment.  If no required reviewers are set for
  # that environment, the workflow will continue without requiring anyone to approve the deployment.
  stakeholder-approval:
    needs: [set-vars]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    environment: '${{ github.event.inputs.environment }} Stakeholder Approval' # Use inputs context because env context is not available to environment:
    steps:
      - run: echo "The current environment is ${{ env.ENVIRONMENT }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."
      - name: Approval Received
        run: echo "Stakeholder approval was received"

  # This job needs to run for all environments because tf-plan relies
  # on it but the steps inside this job will only run for the Prod env.
  validate-tag-is-in-main-for-prod-deploys:
    needs: [set-vars, stakeholder-approval]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    steps:
      - run: echo "The current environment is ${{ env.ENVIRONMENT }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."

      # In this job, always checkout the default branch (not the branch that was provided as an input).  Also use
      # fetch-depth: 0 to retrieve the history and tags so we can check if a tag is reachable from the default branch.
      - name: Checkout Repository
        if: env.ENVIRONMENT == 'prod'
        uses: actions/checkout@v3
        with:
          ref: 'main' # TODO: verify the name of your default branch
          fetch-depth: 0

      - uses: im-open/is-tag-reachable-from-default-branch@v1.1.0
        if: env.ENVIRONMENT == 'prod'
        with:
          tag: ${{ env.GITHUB_REF }}

  # If you want to verify that the Jira ticket being deployed has the proper attestations, there is an action for that.
  # https://github.com/im-open/verify-fields-on-jira-task
  # Set up a new job, or add to an existing one that makes sense, and add a step with that action.
  # Details on how to use the action can be found in the action's README.

  tf-plan:
    needs: [set-vars, validate-tag-is-in-main-for-prod-deploys]
    runs-on: [self-hosted, ubuntu-20.04]
    environment: ${{ github.event.inputs.environment }} # Use inputs context because env context is not available to environment:
    env:
      PAGERDUTY_WINDOW_DESC: 'Deploying Infrastructure to the ${{ github.event.inputs.environment }} environment from GitHub Actions' # TODO: Verify this description
      PAGERDUTY_WINDOW_IN_MIN: 30 # TODO: Verify the length of your PD Maintenance Window

    defaults:
      run:
        shell: bash
        working-directory: '${{ env.TF_WORKING_DIR }}'

    outputs:
      tf_plan_name: ${{ steps.upload.outputs.tf_plan_name }}
      maintenance_window_id: ${{ steps.open-window.outputs.maintenance-window-id }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          ref: ${{ env.GITHUB_REF }}

      - run: echo "The current environment is ${{ env.ENVIRONMENT }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."

      # Allows pulling modules from the repo instead of artifactory
      - name: Setup SSH Keys and known_hosts
        uses: im-open/setup-deploy-keys@v1.1.2
        with:
          deploy-key-info: ${{ env.SSH_DEPLOY_KEY_INFO }}

      - name: Open a PagerDuty Maintenance Window
        id: open-window
        uses: im-open/open-pagerduty-maintenance-window@v1.2.2
        with:
          pagerduty-api-key: ${{ secrets.PAGERDUTY_API_KEY }} # This is an org-level secret
          description: '${{ env.PAGERDUTY_WINDOW_DESC }}'
          minutes: ${{ env.PAGERDUTY_WINDOW_IN_MIN }}
          service-id: ${{ secrets.PAGERDUTY_SERVICE_ID }} # This is an env-level secret
          #service-ids: '' # TODO: Provide a comma separated list if there are multiple ids. 'PD01,PD02,PD03'

      - name: AZ Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Terraform
        id: setup
        uses: hashicorp/setup-terraform@v2.0.2
        with:
          terraform_version: '${{ env.TF_VERSION }}'

      - name: Terraform Init
        id: init
        run: terraform init

      # TODO: Remove the pagerduty token if not configuring pagerduty.  If using pagerduty verify 'pagerduty_token' is the name of the variable that tf accepts as the variable
      # TODO: Add any other secrets that would be required for a tf plan to succeed.  Since this is a multi-line command every line except the last will need a \ on the end of it
      # PAGERDUTY_API_KEY is an org-level secret
      # This will run a plan and output it to a file.  The file is then uploaded to azure storage so it can be used later in the apply.
      - name: Terraform Plan
        id: plan
        run: |
          mkdir plans
          terraform plan -no-color -lock-timeout=90s \
            -var="pagerduty_token=${{ secrets.PAGERDUTY_API_KEY }}" \
            -out=./plans/tfplan

      - name: Upload plan to blob storage
        id: upload
        shell: pwsh
        run: |
          $terraformPlanName = "$(Get-Date -Format 'yyyyMMdd-HHmmss').plan.zip"
          $terraformBlobName = "plans/$terraformPlanName"

          Add-Type -Assembly "System.IO.Compression.FileSystem"
          [System.IO.Compression.ZipFile]::CreateFromDirectory("plans", $terraformPlanName)

          echo "Terraform Plan Name: $terraformPlanName"
          echo "current directory:"
          ls -R

          echo "Uploading tf plan to azure storage account ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }}"
          $key = az storage account keys list --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --resource-group ${{ needs.set-vars.outputs.RESOURCE_GROUP }} --query [0].value -o tsv
          az storage blob upload --no-progress --auth-mode key --account-key $key --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --container-name ${{ env.PLAN_STORAGE_CONTAINER }} --file $terraformPlanName --name $terraformBlobName
          echo "The plan was successfully uploaded"

          echo "::set-output name=tf_plan_name::$terraformPlanName"

      - name: Azure logout
        run: |
          az logout
          az cache purge
          az account clear

  # This job targets the Terraform Approval environment.  This will break the workflow and give one of the
  # required reviewers for this environment a chance to look at the plan in the previous job and approve it.
  tf-plan-manual-approval:
    needs: [set-vars, tf-plan]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    environment: 'Terraform Approval' # TODO: Add required reviewers to this environment in GitHub.  This should be anyone who can review a terraform plan and proceed with the deployment
    steps:
      - run: echo "The current environment is ${{ env.ENVIRONMENT }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."

      - name: Approval Received
        run: echo "Approval on the tf plan was received"

  tf-apply:
    needs: [set-vars, tf-plan, tf-plan-manual-approval]
    runs-on: [self-hosted, ubuntu-20.04]
    environment: ${{ github.event.inputs.environment }} # Use inputs context because env context is not available to environment:

    defaults:
      run:
        shell: bash
        working-directory: '${{ env.TF_WORKING_DIR }}'

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          ref: ${{ env.GITHUB_REF }}

      - run: echo "The current environment is ${{ env.ENVIRONMENT }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."

      # Allows pulling modules from the repo instead of artifactory
      - name: Setup SSH Keys and known_hosts
        uses: im-open/setup-deploy-keys@v1.1.2
        with:
          deploy-key-info: ${{ env.SSH_DEPLOY_KEY_INFO }}

      - name: AZ Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }} # This is an env-level secret

      - name: Setup Terraform
        id: setup
        uses: hashicorp/setup-terraform@v2.0.2
        with:
          terraform_version: '${{ env.TF_VERSION }}'

      - name: Download blob
        shell: pwsh
        run: |
          mkdir plans
          echo "Current working directory: $pwd"
          $terraformBlobName = "plans/${{ needs.tf-plan.outputs.tf_plan_name }}"
          echo "The blob name is: $terraformBlobName"

          Write-Host "Download blob to ./plans"
          $key = az storage account keys list --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --resource-group ${{ needs.set-vars.outputs.RESOURCE_GROUP }} --query [0].value -o tsv
          az storage blob download --no-progress --auth-mode key --account-key $key --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --container-name ${{ env.PLAN_STORAGE_CONTAINER }} --file $pwd/$terraformBlobName --name $terraformBlobName

          try {
            [System.IO.Compression.ZipFile]::ExtractToDirectory("$pwd/$terraformBlobName", "$pwd/plans")
          }
          catch {
            # Even though it hits this catch block the archive is extracted as expected.  No good explanation.
          }

          Write-Host "Zip extracted"

      - name: Terraform Init
        id: init
        run: terraform init

      - name: Terraform Apply
        run: terraform apply -auto-approve -no-color -lock-timeout=90s -input=false ./plans/tfplan

      - name: Azure logout
        run: |
          az logout
          az cache purge
          az account clear

      - name: Close the PagerDuty Maintenance Window
        uses: im-open/close-pagerduty-maintenance-window@v1.1.2
        with:
          pagerduty-api-key: ${{ secrets.PAGERDUTY_API_KEY }} # This is an org-level secret
          maintenance-window-id: ${{ needs.tf-plan.outputs.maintenance_window_id }}

  update-deployment-board-and-send-teams-notification:
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    needs: [set-vars, tf-apply]
    if: always()
    steps:
      - run: echo "The current environment is ${{  env.ENVIRONMENT  }}.  The branch/tag/sha is ${{ env.GITHUB_REF }}."

      # If you want to automatically transition a deployment task in Jira based on the success or failure of this workflow, this job would be a good place for that.
      # There is an action that can do just that: https://github.com/im-open/transition-jira-tasks-by-query
      # Details on how to set up that action can be found in the action's README.
      # There are secrets for the username and password already set up as org level secrets called JIRA_USERNAME and JIRA_PASSWORD.

      - uses: im-open/workflow-conclusion@v2.1.2
        id: conclusion
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }} # Special per-job token generated by GH for interacting with the repo

      # https://github.com/im-practices/git-er-done/blob/main/actions/deployment-board.md
      - name: Update Deployment Board
        if: always()
        uses: im-open/update-deployment-board@v1.5.2
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }} # Special per-job token generated by GH for interacting with the repo
          environment: ${{ env.ENVIRONMENT }}
          board-number: '' # TODO: Add the automated deployment board number or remove if not using an automated deployment project board.
          ref: ${{ env.GITHUB_REF }}
          #deployable-type: '' # TODO:  If there are multiple deployables in the repository, add a string type like MFE/DB/API
          deploy-status: ${{ steps.conclusion.outputs.workflow_conclusion }}
          timezone: ${{ env.TIMEZONE }}

      - name: Send Status to Teams
        if: always()
        uses: im-open/post-status-to-teams-action@v1.3.2
        with:
          title: Deploying <project-name> Terraform to Azure to ${{ env.ENVIRONMENT }} # TODO: Replace <project-name> with your project
          workflow-status: ${{ steps.conclusion.outputs.workflow_conclusion }}
          workflow-type: Deploy
          teams-uri: ${{ secrets.MS_TEAMS_URI }} # This is a repo-level secret (unless 'environment:' has been added to the job)
          timezone: ${{ env.TIMEZONE }}
          custom-facts: |
            [
              { "name": "Workflow", "value": "${{ github.workflow }}" },
              { "name": "Run", "value": "${{ github.run_id }}" },
              { "name": "Actor", "value": "${{ github.actor }}" },
              { "name": "Branch/Tag/SHA", "value": "${{ env.GITHUB_REF }}" }
            ]
