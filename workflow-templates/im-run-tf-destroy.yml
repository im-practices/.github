# Workflow Code: HostileMacaw_v14    DO NOT REMOVE
# Purpose:
#    Destroys the resources created by a terraform configuration when someone kicks it off manually.
#
# Frequency:
#    - This workflow should only be used once per repository
#
# Projects to use this Template with:
#    -  Terraform (Optional Template)
#
# TODO Prerequisites
#    - Ensure each of the repo-level and env-level secrets used in this workflow have been populated by an admin in your repository.

name: Terraform Destroy
run-name: Terraform destroy ${{ inputs.root-module }} at ${{ inputs.branch-tag-sha }}
on:
  workflow_dispatch:
    inputs:
      # This is required because a tf init has to be performed before the terraform destroy command
      branch-tag-sha:
        description: The branch, tag or sha of the terraform that has the configuration of the resources that will be destroyed.
        required: true
      root-module:
        description: The directory containing the Terraform root module to destroy
        required: true
        type: choice
        options: # TODO: Update for the root modules that are available
          - dev
          - qa
          - stage
          - demo
          - uat
          - prod
          - stage-secondary
          - prod-secondary
      tf-targets:
        description: 'Targeted Destroys: format -target module.your-module.resource'
        required: false

env:
  DEPLOYMENT_DESC: 'Destroying <project-name> ${{ inputs.tf-targets }} ${{ inputs.root-module }} via Terraform at ${{ inputs.branch-tag-sha }}' # TODO: Replace <project-name> with your project
  GITHUB_REF: ${{ inputs.branch-tag-sha  }}
  TIMEZONE: 'america/denver' # TODO: Verify timezone
  PLAN_STORAGE_CONTAINER: 'tfstate'
  # The following ARM_* secrets are env-level secrets
  ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
  ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
  ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
  ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
  ARM_ENVIRONMENT: 'public'
  TF_IN_AUTOMATION: 'true'
  TF_VERSION: '~>1.4.0' #TODO:  Verify your version of terraform.
  TF_WORKING_DIR: './infrastructure/${{ inputs.root-module }}' # TODO: Verify this directory is correct for your repository (older projects may not be inside of an infrastructure folder)
  # The following SSH_* secrets are org-level secrets
  SSH_KEY_STORAGE_ACCOUNT: ${{ secrets.SSH_STORAGE_ACCOUNT }}
  SSH_KEY_NETWORK_INFO: ${{ secrets.SSH_NETWORK_INFO }}
  SSH_KEY_AAD_GROUP_MEMBERS: ${{ secrets.SSH_AAD_GROUP_MEMBERS }}
  SSH_DEPLOY_KEY_INFO: |
    [
      { "orgAndRepo": "im-platform/storage-account-network-rules", "envName" : "SSH_KEY_STORAGE_ACCOUNT" },
      { "orgAndRepo": "im-platform/network-information", "envName" : "SSH_KEY_NETWORK_INFO" },
      { "orgAndRepo": "im-platform/aad-group-members", "envName" : "SSH_KEY_AAD_GROUP_MEMBERS" }
    ]

jobs:
  set-vars:
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners

    outputs:
      # To use these values: ${{ needs.set-vars.outputs.<OUTPUT_NAME> }}
      TARGET_RESOURCE_GROUP: ${{ steps.set-variables.outputs.TARGET_RESOURCE_GROUP }}
      PRIMARY_RESOURCE_GROUP: ${{ steps.set-variables.outputs.PRIMARY_RESOURCE_GROUP }}
      STORAGE_ACCOUNT: ${{ steps.set-variables.outputs.STORAGE_ACCOUNT }}
      GITHUB_SECRETS_ENVIRONMENT: ${{ steps.set-variables.outputs.GITHUB_SECRETS_ENVIRONMENT }}

    steps:
      - run: |
          echo $'
          | Build Arguments | Value                    |
          | ---             |  ---                     |
          | Root module     | `${{ inputs.root-module }}` |
          | Branch/Tag/Sha  | `${{ env.GITHUB_REF }}`  |
          | Workflow Source | `${{ github.ref_name }}` - SHA: `${{ github.sha }}` |' >> $GITHUB_STEP_SUMMARY

      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Verify Ref Exists
        uses: im-open/verify-git-ref@v1.2
        with:
          branch-tag-sha: ${{ env.GITHUB_REF }}

      # For more information and best practices on the usage and options available
      # for this action go to: https://github.com/im-open/set-environment-variables-by-scope#usage-instructions
      - name: Set Variables
        id: set-variables
        uses: im-open/set-environment-variables-by-scope@v1.1
        with:
          scope: ${{ inputs.root-module }}
          create-output-variables: true
        env:
          # Resource group you are targeting for deploy.  Also this variable is used to delete and re-create azure locks.
          # TODO: Add the NA27 (West Central US) Resource Group to the stage-secondary/prod-secondary to the variables.
          # TODO: Add the NA26 (West US2) Resource Groups to dev/qa/stage/demo/uat/prod to the variables
          TARGET_RESOURCE_GROUP@dev: ''
          TARGET_RESOURCE_GROUP@qa: ''
          TARGET_RESOURCE_GROUP@stage: ''
          TARGET_RESOURCE_GROUP@stage-secondary: ''
          TARGET_RESOURCE_GROUP@demo: ''
          TARGET_RESOURCE_GROUP@uat: ''
          TARGET_RESOURCE_GROUP@prod: ''
          TARGET_RESOURCE_GROUP@prod-secondary: ''

          # Resource group holding the state storage account and managed service identities
          # TODO: Add the Stage/Prod NA26 (West US2) Resource Groups below.
          PRIMARY_RESOURCE_GROUP@dev: ''
          PRIMARY_RESOURCE_GROUP@qa: ''
          PRIMARY_RESOURCE_GROUP@stage stage-secondary: ''
          PRIMARY_RESOURCE_GROUP@demo: ''
          PRIMARY_RESOURCE_GROUP@prod prod-secondary: ''

          # This variable is used to upload and download blobs from blob storage
          # TODO: Add the NA26 (West US2) Storage Accounts to the variables
          STORAGE_ACCOUNT@dev: ''
          STORAGE_ACCOUNT@qa: ''
          STORAGE_ACCOUNT@stage stage-secondary: ''
          STORAGE_ACCOUNT@demo: ''
          STORAGE_ACCOUNT@uat: ''
          STORAGE_ACCOUNT@prod prod-secondary: ''

          # Used for getting Azure Credentials Secrets
          GITHUB_SECRETS_ENVIRONMENT@dev qa stage prod demo: '${{ inputs.root-module }}'
          GITHUB_SECRETS_ENVIRONMENT@stage-secondary: 'stage'
          GITHUB_SECRETS_ENVIRONMENT@prod-secondary: 'prod'

  # Each env has their own stakeholder approval environment.  If no required reviewers are set for
  # that environment, the workflow will continue without requiring anyone to approve the deployment.
  stakeholder-approval:
    needs: [set-vars]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    environment: '${{ needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT }} Stakeholder Approval' # Use inputs context because env context is not available to environment:
    steps:
      - name: Approval Received
        run: echo "Stakeholder approval was received"

  # This job needs to run for all environments because tf-plan relies
  # on it but the steps inside this job will only run for the Prod env.
  validate-tag-is-in-main-for-prod-deploys:
    needs: [set-vars]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    steps:
      # In this job, always checkout the default branch (not the branch that was provided as an input).  Also use
      # fetch-depth: 0 to retrieve the history and tags so we can check if a tag is reachable from the default branch.
      - name: Checkout Repository
        if: needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'prod'
        uses: actions/checkout@v3
        with:
          ref: 'main' # TODO: verify the name of your default branch
          fetch-depth: 0

      - uses: im-open/is-tag-reachable-from-default-branch@v1.1
        if: needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'prod'
        with:
          tag: ${{ env.GITHUB_REF }}

  # If you want to verify that the Jira ticket being deployed has the proper attestations, there is an action for that.
  # https://github.com/im-open/verify-fields-on-jira-task
  # Set up a new job, or add to an existing one that makes sense, and add a step with that action.
  # Details on how to use the action can be found in the action's README.

  tf-plan:
    needs: [set-vars, validate-tag-is-in-main-for-prod-deploys]
    runs-on: [self-hosted, ubuntu-20.04]
    environment: ${{ needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT }}

    defaults:
      run:
        shell: bash
        working-directory: '${{ env.TF_WORKING_DIR }}'

    outputs:
      tf_plan_name: ${{ steps.upload.outputs.tf_plan_name }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          ref: ${{ env.GITHUB_REF }}

      # Allows pulling modules from the repo instead of artifactory
      - name: Setup SSH Keys and known_hosts
        uses: im-open/setup-deploy-keys@v1.1
        with:
          deploy-key-info: ${{ env.SSH_DEPLOY_KEY_INFO }}

      - name: AZ Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Terraform
        id: setup
        uses: hashicorp/setup-terraform@v2.0.3
        with:
          terraform_version: '${{ env.TF_VERSION }}'

      - name: Terraform Init
        id: init
        run: terraform init

      # TODO: Remove the pagerduty token if not configuring pagerduty.  If using pagerduty verify 'pagerduty_token' is the name of the variable that tf accepts as the variable
      # TODO: Add any other secrets that would be required for a tf plan to succeed.  Since this is a multi-line command every line except the last will need a \ on the end of it
      # PAGERDUTY_API_KEY is an org-level secret
      # This will run a plan and output it to a file.  The file is then uploaded to azure storage so it can be used later in the apply.
      - name: Terraform Plan
        id: plan
        run: |
          mkdir plans
          terraform plan -destroy -no-color -lock-timeout=90s \
            -var="pagerduty_token=${{ secrets.PAGERDUTY_API_KEY }}" \
            -out=./plans/tfplan ${{ inputs.tf-targets }}

      - name: Output Plan Results Summary
        id: plan-results-output
        continue-on-error: true
        run: |
          plan=$(cat <<'EOF'
          ${{ format('{0}{1}', steps.plan.outputs.stdout, steps.plan.outputs.stderr) }}
          EOF
          )

          plan_results=$(echo "$plan" | grep -e "Plan:" -e "No changes." -e "# module.") # TODO: Add any unique filters required in your pipeline.  IE terraform-f5 output doesn't have module. prefix.
          echo "Plan Results Returned:"
          echo "$plan_results "       
          if [[ -z "$plan_results" ]]; then
            plan_results="Errors were found in terraform plan"
          fi

          cat >> $GITHUB_STEP_SUMMARY << EOL
          ## Plan Results Summary [${{ inputs.root-module }}]

          \`\`\`js
          $plan_results
          \`\`\`
          EOL

      - name: Upload plan to blob storage
        id: upload
        shell: pwsh
        run: |
          $terraformPlanName = "$(Get-Date -Format 'yyyyMMdd-HHmmss').plan.zip"
          $terraformBlobName = "plans/$terraformPlanName"

          Add-Type -Assembly "System.IO.Compression.FileSystem"
          [System.IO.Compression.ZipFile]::CreateFromDirectory("plans", $terraformPlanName)

          echo "Terraform Plan Name: $terraformPlanName"
          echo "current directory:"
          ls -R

          echo "Uploading tf plan to azure storage account ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }}"
          $key = az storage account keys list --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --resource-group ${{ needs.set-vars.outputs.PRIMARY_RESOURCE_GROUP }} --query [0].value -o tsv
          az storage blob upload --no-progress --auth-mode key --account-key $key --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --container-name ${{ env.PLAN_STORAGE_CONTAINER }} --file $terraformPlanName --name $terraformBlobName
          echo "The plan was successfully uploaded"

          echo "tf_plan_name=$terraformPlanName" >> $env:GITHUB_OUTPUT

      - name: Azure logout
        run: |
          az logout
          az cache purge
          az account clear

  # This job targets the Terraform Approval environment.  This will break the workflow and give one of the
  # required reviewers for this environment a chance to look at the plan in the previous job and approve it.
  tf-plan-manual-approval:
    needs: [set-vars, tf-plan]
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    environment: 'Terraform Approval' # TODO: Add required reviewers to this environment in GitHub.  This should be anyone who can review a terraform plan and proceed with the deployment
    steps:
      - name: Approval Received
        run: echo "Approval on the tf plan was received"

  tf-apply:
    needs: [set-vars, tf-plan, tf-plan-manual-approval, stakeholder-approval]
    runs-on: [self-hosted, ubuntu-20.04]
    environment: ${{ needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT }}

    defaults:
      run:
        shell: bash
        working-directory: '${{ env.TF_WORKING_DIR }}'

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          ref: ${{ env.GITHUB_REF }}

      # Allows pulling modules from the repo instead of artifactory
      - name: Setup SSH Keys and known_hosts
        uses: im-open/setup-deploy-keys@v1.1
        with:
          deploy-key-info: ${{ env.SSH_DEPLOY_KEY_INFO }}

      - name: AZ Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }} # This is an env-level secret

      - name: Setup Terraform
        id: setup
        uses: hashicorp/setup-terraform@v2.0.3
        with:
          terraform_version: '${{ env.TF_VERSION }}'

      - name: Download blob
        shell: pwsh
        run: |
          mkdir plans
          echo "Current working directory: $pwd"
          $terraformBlobName = "plans/${{ needs.tf-plan.outputs.tf_plan_name }}"
          echo "The blob name is: $terraformBlobName"

          Write-Host "Download blob to ./plans"
          $key = az storage account keys list --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --resource-group ${{ needs.set-vars.outputs.PRIMARY_RESOURCE_GROUP }} --query [0].value -o tsv
          az storage blob download --no-progress --auth-mode key --account-key $key --account-name ${{ needs.set-vars.outputs.STORAGE_ACCOUNT }} --container-name ${{ env.PLAN_STORAGE_CONTAINER }} --file $pwd/$terraformBlobName --name $terraformBlobName

          try {
            [System.IO.Compression.ZipFile]::ExtractToDirectory("$pwd/$terraformBlobName", "$pwd/plans")
          }
          catch {
            # Even though it hits this catch block the archive is extracted as expected.  No good explanation.
          }

          Write-Host "Zip extracted"

      # TODO: Uncomment if you have azure locks in stage and prod
      # - name: Delete RGRP Azure Locks
      #   id: remove-locks
      #   if: needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'prod' || needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'stage'
      #   shell: pwsh
      #   env:
      #     LOCK_NAME: ${{ needs.set-vars.outputs.TARGET_RESOURCE_GROUP }}-delete-locks
      #     RGRP: ${{ needs.set-vars.outputs.TARGET_RESOURCE_GROUP }}
      #   run: |
      #     az group lock delete --name $Env:LOCK_NAME --resource-group $Env:RGRP
      #     While(
      #       $(az group lock list --resource-group $Env:RGRP --output tsv --query "[?name=='${$Env:LOCK_NAME}'].id")
      #     ){
      #       Start-Sleep -s 0.5
      #     }

      - name: Terraform Init
        id: init
        run: terraform init

      - name: Terraform Destroy
        run: terraform apply -auto-approve -no-color -lock-timeout=90s -input=false ./plans/tfplan

      # TODO: Uncomment if you have azure locks in stage and prod
      # - name: Add RGRP Azure Locks
      #   id: add-locks
      #   if: needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'prod' || needs.set-vars.outputs.GITHUB_SECRETS_ENVIRONMENT == 'stage'
      #   run: |
      #     az group lock create --name "${{ needs.set-vars.outputs.TARGET_RESOURCE_GROUP }}-delete-locks"  --resource-group "${{ needs.set-vars.outputs.TARGET_RESOURCE_GROUP }}" --lock-type CanNotDelete

      - name: Azure logout
        run: |
          az logout
          az cache purge
          az account clear

  update-deployment-board-and-send-teams-notification:
    runs-on: ubuntu-latest # Force this to run on github-hosted runner by using a tag that does not exist on self-hosted runners
    needs: [set-vars, tf-apply]
    if: always()
    steps:
      # If you want to automatically transition a deployment task in Jira based on the success or failure of this workflow, this job would be a good place for that.
      # There is an action that can do just that: https://github.com/im-open/transition-jira-tasks-by-query
      # Details on how to set up that action can be found in the action's README.
      # There are secrets for the username and password already set up as org level secrets called JIRA_USERNAME and JIRA_PASSWORD.

      - uses: im-open/workflow-conclusion@v2.1
        id: conclusion
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }} # Special per-job token generated by GH for interacting with the repo

      # TODO: Add Columns Stage-Secondary and Prod-Secondary to your Deployment Board
      # https://github.com/im-practices/git-er-done/blob/main/actions/deployment-board.md
      - name: Update Deployment Board
        if: always()
        uses: im-open/update-deployment-board@v1.5
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }} # Special per-job token generated by GH for interacting with the repo
          environment: ${{ inputs.root-module }}
          board-number: '' # TODO: Add the automated deployment board number or remove if not using an automated deployment project board.
          ref: ${{ env.GITHUB_REF }}
          #deployable-type: '' # TODO:  If there are multiple deployables in the repository, add a string type like MFE/DB/API
          deploy-status: ${{ steps.conclusion.outputs.workflow_conclusion == 'success' && 'ðŸ’¥ destroyed' || steps.conclusion.outputs.workflow_conclusion}}
          timezone: ${{ env.TIMEZONE }}

      - name: Send Status to Teams
        if: always()
        uses: im-open/post-status-to-teams-action@v1.3
        with:
          title: ${{ env.DEPLOYMENT_DESC }}
          workflow-status: ${{ steps.conclusion.outputs.workflow_conclusion }}
          workflow-type: Deploy
          teams-uri: ${{ secrets.MS_TEAMS_URI }} # This is a repo-level secret (unless 'environment:' has been added to the job)
          timezone: ${{ env.TIMEZONE }}
          custom-facts: |
            [
              { "name": "Workflow", "value": "${{ github.workflow }}" },
              { "name": "Run", "value": "${{ github.run_id }}" },
              { "name": "Actor", "value": "${{ github.actor }}" },
              { "name": "Branch/Tag/SHA", "value": "${{ env.GITHUB_REF }}" }
            ]
